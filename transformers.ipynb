{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:36.186992Z","iopub.execute_input":"2022-06-27T20:24:36.187415Z","iopub.status.idle":"2022-06-27T20:24:36.219505Z","shell.execute_reply.started":"2022-06-27T20:24:36.187334Z","shell.execute_reply":"2022-06-27T20:24:36.218743Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms as T # for simplifying the transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split\nfrom torchvision import models","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:36.382147Z","iopub.execute_input":"2022-06-27T20:24:36.382411Z","iopub.status.idle":"2022-06-27T20:24:38.198059Z","shell.execute_reply.started":"2022-06-27T20:24:36.382388Z","shell.execute_reply":"2022-06-27T20:24:38.197260Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# remove warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:38.199746Z","iopub.execute_input":"2022-06-27T20:24:38.200296Z","iopub.status.idle":"2022-06-27T20:24:38.206437Z","shell.execute_reply.started":"2022-06-27T20:24:38.200260Z","shell.execute_reply":"2022-06-27T20:24:38.205656Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## Now, we import timm, torchvision image models\n!pip install timm # kaggle doesnt have it installed by default\nimport timm\nfrom timm.loss import LabelSmoothingCrossEntropy # This is better than normal nn.CrossEntropyLoss","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:38.207887Z","iopub.execute_input":"2022-06-27T20:24:38.208664Z","iopub.status.idle":"2022-06-27T20:24:56.988352Z","shell.execute_reply.started":"2022-06-27T20:24:38.208628Z","shell.execute_reply":"2022-06-27T20:24:56.987424Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:56.990525Z","iopub.execute_input":"2022-06-27T20:24:56.990826Z","iopub.status.idle":"2022-06-27T20:24:56.996242Z","shell.execute_reply.started":"2022-06-27T20:24:56.990797Z","shell.execute_reply":"2022-06-27T20:24:56.995562Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import sys\nfrom tqdm import tqdm\nimport time\nimport copy","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:56.997394Z","iopub.execute_input":"2022-06-27T20:24:56.998297Z","iopub.status.idle":"2022-06-27T20:24:57.008824Z","shell.execute_reply.started":"2022-06-27T20:24:56.998259Z","shell.execute_reply":"2022-06-27T20:24:57.007963Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_classes(data_dir):\n    all_data = datasets.ImageFolder(data_dir)\n    return all_data.classes","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:57.010127Z","iopub.execute_input":"2022-06-27T20:24:57.010546Z","iopub.status.idle":"2022-06-27T20:24:57.018141Z","shell.execute_reply.started":"2022-06-27T20:24:57.010511Z","shell.execute_reply":"2022-06-27T20:24:57.017267Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_data_loaders(data_dir, batch_size, train = False):\n    if train:\n        #train\n        transform = T.Compose([\n            T.RandomHorizontalFlip(),\n            T.RandomVerticalFlip(),\n            T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.25),\n            T.Resize(256),\n            T.CenterCrop(224),\n            T.ToTensor(),\n            T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet means\n            T.RandomErasing(p=0.2, value='random')\n        ])\n        train_data = datasets.ImageFolder(os.path.join(data_dir, \"birds/birds/\"), transform = transform)\n        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        return train_loader, len(train_data)\n    else:\n        # test\n        transform = T.Compose([ # We dont need augmentation for test transforms\n            T.Resize(256),\n            T.CenterCrop(224),\n            T.ToTensor(),\n            T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet means\n        ])\n        test_data = datasets.ImageFolder(os.path.join(data_dir, \"submission_test/\"), transform=transform)\n        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        return test_loader, len(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:57.019227Z","iopub.execute_input":"2022-06-27T20:24:57.019643Z","iopub.status.idle":"2022-06-27T20:24:57.032375Z","shell.execute_reply.started":"2022-06-27T20:24:57.019592Z","shell.execute_reply":"2022-06-27T20:24:57.031261Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/iais22-birds/\"","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:57.034242Z","iopub.execute_input":"2022-06-27T20:24:57.034712Z","iopub.status.idle":"2022-06-27T20:24:57.041969Z","shell.execute_reply.started":"2022-06-27T20:24:57.034674Z","shell.execute_reply":"2022-06-27T20:24:57.041178Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"(train_loader, train_data_len) = get_data_loaders(dataset_path, 128, train=True)\n(test_loader, test_data_len) = get_data_loaders(dataset_path, 128, train=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:24:57.042988Z","iopub.execute_input":"2022-06-27T20:24:57.043241Z","iopub.status.idle":"2022-06-27T20:25:11.753788Z","shell.execute_reply.started":"2022-06-27T20:24:57.043219Z","shell.execute_reply":"2022-06-27T20:25:11.752957Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"classes = get_classes(\"/kaggle/input/iais22-birds/birds/birds/\")\nprint(classes, len(classes))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:11.756776Z","iopub.execute_input":"2022-06-27T20:25:11.757391Z","iopub.status.idle":"2022-06-27T20:25:12.168103Z","shell.execute_reply.started":"2022-06-27T20:25:11.757353Z","shell.execute_reply":"2022-06-27T20:25:12.167301Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataloaders = {\n    \"train\": train_loader\n}\ndataset_sizes = {\n    \"train\": train_data_len\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:12.169315Z","iopub.execute_input":"2022-06-27T20:25:12.169705Z","iopub.status.idle":"2022-06-27T20:25:12.176329Z","shell.execute_reply.started":"2022-06-27T20:25:12.169665Z","shell.execute_reply":"2022-06-27T20:25:12.175550Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(len(train_loader), len(test_loader))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:12.177732Z","iopub.execute_input":"2022-06-27T20:25:12.178087Z","iopub.status.idle":"2022-06-27T20:25:12.183791Z","shell.execute_reply.started":"2022-06-27T20:25:12.178051Z","shell.execute_reply":"2022-06-27T20:25:12.182897Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(train_data_len, test_data_len)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:12.185143Z","iopub.execute_input":"2022-06-27T20:25:12.186885Z","iopub.status.idle":"2022-06-27T20:25:12.192829Z","shell.execute_reply.started":"2022-06-27T20:25:12.186841Z","shell.execute_reply":"2022-06-27T20:25:12.191986Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# now, for the model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:12.194266Z","iopub.execute_input":"2022-06-27T20:25:12.194937Z","iopub.status.idle":"2022-06-27T20:25:12.253337Z","shell.execute_reply.started":"2022-06-27T20:25:12.194900Z","shell.execute_reply":"2022-06-27T20:25:12.252424Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:12.254755Z","iopub.execute_input":"2022-06-27T20:25:12.255165Z","iopub.status.idle":"2022-06-27T20:25:20.436180Z","shell.execute_reply.started":"2022-06-27T20:25:12.255082Z","shell.execute_reply":"2022-06-27T20:25:20.435417Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"for param in model.parameters(): #freeze model\n    param.requires_grad = False\n\nn_inputs = model.head.in_features\nmodel.head = nn.Sequential(\n    nn.Linear(n_inputs, 512),\n    nn.ReLU(),\n    nn.Dropout(0.3),\n    nn.Linear(512, len(classes))\n)\nmodel = model.to(device)\nprint(model.head)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:20.437641Z","iopub.execute_input":"2022-06-27T20:25:20.438161Z","iopub.status.idle":"2022-06-27T20:25:25.083936Z","shell.execute_reply.started":"2022-06-27T20:25:20.438122Z","shell.execute_reply":"2022-06-27T20:25:25.082358Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"criterion = LabelSmoothingCrossEntropy()\ncriterion = criterion.to(device)\noptimizer = optim.Adam(model.head.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:25.085436Z","iopub.execute_input":"2022-06-27T20:25:25.085853Z","iopub.status.idle":"2022-06-27T20:25:25.091528Z","shell.execute_reply.started":"2022-06-27T20:25:25.085810Z","shell.execute_reply":"2022-06-27T20:25:25.090430Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# lr scheduler\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:25.092954Z","iopub.execute_input":"2022-06-27T20:25:25.093549Z","iopub.status.idle":"2022-06-27T20:25:25.114302Z","shell.execute_reply.started":"2022-06-27T20:25:25.093501Z","shell.execute_reply":"2022-06-27T20:25:25.113536Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print(\"-\"*10)\n        \n        for phase in ['train']: # We do training phase per epoch\n            if phase == 'train':\n                model.train() # model to training mode\n            else:\n                model.eval() # model to evaluate\n            \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n                    m = nn.Softmax(dim=1)\n                    outputs = m(model(inputs))\n                    _, preds = torch.max(outputs, 1) # used for accuracy\n                    loss = criterion(outputs, labels)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n            if phase == 'train':\n                scheduler.step() # step at end of epoch\n            \n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n            \n            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n            \n        print()\n    time_elapsed = time.time() - since # slight error\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    \n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:25.116583Z","iopub.execute_input":"2022-06-27T20:25:25.117220Z","iopub.status.idle":"2022-06-27T20:25:25.130238Z","shell.execute_reply.started":"2022-06-27T20:25:25.117181Z","shell.execute_reply":"2022-06-27T20:25:25.129379Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T20:25:25.131550Z","iopub.execute_input":"2022-06-27T20:25:25.132031Z","iopub.status.idle":"2022-06-27T21:01:11.104973Z","shell.execute_reply.started":"2022-06-27T20:25:25.131994Z","shell.execute_reply":"2022-06-27T21:01:11.102617Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_loss = 0.0\nclass_correct = list(0 for i in range(len(classes)))\nclass_total = list(0 for i in range(len(classes)))\nmodel_ft.eval()\n\nfor data, target in tqdm(test_loader):\n    data, target = data.to(device), target.to(device)\n    with torch.no_grad(): # turn off autograd for faster testing\n        output = model_ft(data)\n        loss = criterion(output, target)\n    test_loss = loss.item() * data.size(0)\n    _, pred = torch.max(output, 1)\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.cpu().numpy())\n    if len(target) == 128:\n        for i in range(128):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\ntest_loss = test_loss / test_data_len\nprint('Test Loss: {:.4f}'.format(test_loss))\nfor i in range(len(classes)):\n    if class_total[i] > 0:\n        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n        ))\n    else:\n        print(\"Test accuracy of %5s: NA\" % (classes[i]))\nprint(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T21:01:11.106462Z","iopub.execute_input":"2022-06-27T21:01:11.107107Z","iopub.status.idle":"2022-06-27T21:01:19.717382Z","shell.execute_reply.started":"2022-06-27T21:01:11.107061Z","shell.execute_reply":"2022-06-27T21:01:19.716269Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}